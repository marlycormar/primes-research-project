## Support Vector Machine

### Model Description

The Support Vector Machine (SVM) is a non-parametric and supervised algorithm for classification: the SVM generates a hyper-plane or curve that splits the sample space into two regions, and given a test observation, its classification is based on the region that it falls in.

In detail, the SVM maps the training data into a higher-dimensional space using kernels. Two common kernels are the polynomial kernel, which maps each observation via a polynomial of degree $d$, and the radial kernel, which maps each observation via its distance from a point. As a result, the training data now has a roughly linear decision boundary, so the simpler support vector classifier can be applied: generate a hyperplane $\beta_0+\beta_1 x_{i1}+\dots + \beta_p x_{ip}=0$ that mostly separates the two categories by solving the optimization problem of maximizing $M$, the width of the margin, subject to the conditions:

1.  $\sum_{j=1}^p \beta_j^2 = 1$
2.  $y_i(\beta_0+\beta_1 x_{i1}+\dots + \beta_p x_{ip}) \ge M(1-\epsilon_i)$
3.  $\epsilon_i \ge 0$ and $\sum_{i=1}^n \epsilon_i \le C$.

Here each $\epsilon_i$ is a small error term, and $C$ is parameter for which larger $C$ corresponds to higher tolerance of violations of the margin. We tune these parameters below.

### Model Workflow

```{r, warning=FALSE, message=FALSE}

# Read cleaned data.
cleaned_data <- readr::read_csv(here::here('data', 'cleaned-data.csv'))

```


```{r svm-data-split, cache=TRUE}

set.seed(314)

# Split data into training, validation, and test sets.
data_split <- rsample::initial_validation_split(cleaned_data)
train_data <- rsample::training(data_split)
validation_data <- rsample::validation(data_split)
test_data <- rsample::testing(data_split)

# Create cross-validation collection.
data_cross_val <- rsample::vfold_cv(train_data)

# Save the test data `Recurred`.
test_outcome <- 
  factor(test_data$Recurred)

```


```{r svm-data-recipes, cache=TRUE}

# Create recipe for the data prep.
data_rec <- recipes::recipe(Recurred ~ ., data = train_data) |>
  recipes::step_corr(threshold = 0.6) |>
  recipes::step_normalize(recipes::all_numeric()) |>
  recipes::step_dummy(recipes::all_nominal_predictors())

```

We will create an SVM model specification and workflow indicating the model hyper-parameters: a cost value and `rbf_sigma`, a positive number for radial basis function. To optimize our model, we will use the `tune::tune()` function to find optimal values of these parameters in terms of model accuracy.

```{r svm-workflow, cache=TRUE, echo=TRUE}

# Create model specification.
svm_model_spec <-
  parsnip::svm_rbf(cost = tune::tune(), rbf_sigma = tune::tune()) |>
  parsnip::set_mode('classification') |>
  parsnip::set_engine('kernlab')

# Create model workflow.
svm_workflow <- workflows::workflow() |>
  workflows::add_model(svm_model_spec) |>
  workflows::add_recipe(data_rec)

```


### Model Tuning and Fitting

As we did for KNN, we use parallel computing to fine-tuning our model using the $10$-fold cross validation we set up earlier. We end this section by selecting the best model based on accuracy and the ROC curve.


```{r svm-param-tunning, cache=TRUE, warning=FALSE, echo=TRUE}

#' Check number of available cores.
cores_no <- parallel::detectCores() - 1

#' Start timer.
tictoc::tic()

# Create cores_no clusters.
clusters <- parallel::makeCluster(cores_no)

# Start clusters.
doParallel::registerDoParallel(clusters)

# Fine-tune the model params.
svm_res <- tune::tune_grid(
  object = svm_workflow,
  preprocessor = svm_model_spec,
  resamples = data_cross_val,
  control = tune::control_resamples(save_pred = TRUE)
)

# Select 'best' fit (in terms of accuracy).
svm_best_fit <- 
  svm_res |> 
  tune::select_best(metric = 'accuracy')

# Use the 'best' model params for our final model.
svm_final_workflow <- 
  svm_workflow |>
  tune::finalize_workflow(svm_best_fit)

# Fit our model using the 'best' params.
svm_final_fit <- 
  svm_final_workflow |> 
  tune::last_fit(data_split)

# Stop clusters.
parallel::stopCluster(clusters)

# Stop timer.
tictoc::toc()

# Choose the best model params.
svm_res |> tune::select_best(metric = 'roc_auc')

```

### Model Performance

We then apply our selected model to the test set. The final metrics are given in @tbl-svm-performance.

```{r svn-performance, cache=TRUE, echo=TRUE}

# Use the best fit to make predictions on the test data.
svm_pred <- 
  svm_final_fit |> 
  tune::collect_predictions() |>
  dplyr::mutate(truth = factor(.pred_class))

```


```{r}
#| label: tbl-svm-performance
#| tbl-cap: 'SVM Performance Metrics: Accuracy, Precision, Recall, and Specificity.'
#| tbl-alt: 'SVM Performance Metrics: Accuracy, Precision, Recall, and Specificity.'

# Prepare table's theme.
theme <- reactable::reactableTheme(
  borderColor = "#dfe2e5",
  stripedColor = "#f6f8fa", 
  highlightColor = "#f0f5f9",
  cellPadding = "8px 12px"
)

# Create metrics table.
svm_metrics_table <- list(
  'Accuracy' = yardstick::accuracy_vec(truth = svm_pred[['.pred_class']],
                                       estimate = test_outcome),
  'Precision' = yardstick::precision_vec(truth = svm_pred[['.pred_class']],
                                         estimate = test_outcome),
  'Recall' = yardstick::recall_vec(truth = svm_pred[['.pred_class']],
                                   estimate = test_outcome),
  'Specificity' = yardstick::specificity_vec(truth = svm_pred[['.pred_class']],
                                            estimate = test_outcome)
) |>
  dplyr::bind_cols() |>
  tidyr::pivot_longer(cols = dplyr::everything(), names_to = 'Metric', values_to = 'Value') |>
  dplyr::mutate(Value = round(Value*100, 1))

readr::write_csv(x = svm_metrics_table, file = here::here('data', 'svm-metrics.csv'))

svm_metrics_table |>
  dplyr::mutate(Value = paste0(Value, '%')) |>
  reactable::reactable(
    searchable = FALSE, 
    resizable = TRUE,
    onClick = "expand",
    bordered = TRUE,
    highlight = TRUE, 
    compact = TRUE,
    height = "auto",
    theme = theme
  )

```