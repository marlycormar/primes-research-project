{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "## Support Vector Machine\n",
    "\n",
    "### Model Description\n",
    "\n",
    "Support Vector Machines (SVM) are powerful supervised learning algorithms used for both classification and regression tasks. For classification, SVM works by finding the hyperplane that best separates data points of different classes in a high-dimensional space. The optimal hyperplane is determined by maximizing the margin between the closest points of the classes, known as support vectors.\n",
    "\n",
    "SVM is particularly effective in high-dimensional spaces and is useful when the number of dimensions exceeds the number of samples. It can employ various kernel functions—such as linear, polynomial, and radial basis function (RBF)—to handle non-linear classification by mapping input features into higher-dimensional spaces.\n",
    "\n",
    "The most commonly used kernel in SVM is the Radial Basis Function (RBF) kernel, also known as the Gaussian kernel. The RBF kernel maps input features into an infinite-dimensional space, allowing SVM to create complex decision boundaries. The RBF kernel function is defined as:\n",
    "\n",
    "$$K(X_i, X_j) = e^{- \\frac{|| X_i - X_j ||^2}{2 \\sigma^2}}$$ where $X_i$ and $X_j$ are the input feature vectors, and $\\sigma$ is a parameter that determines the spread of the kernel and controls the influence of individual training samples.\n",
    "\n",
    "### Model Workflow"
   ],
   "id": "550adf78-4b3e-4c3e-8757-418d4dfe5fb8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data already computed in the index.qmd file.\n",
    "data_split <- readRDS(here::here('data/data_split.rds'))\n",
    "data_cross_val <- readRDS(here::here('data/data_cross_val.rds'))\n",
    "test_outcome <- readRDS(here::here('data/test_outcome.rds'))\n",
    "data_rec <- readRDS(here::here('data/data_rec.rds'))\n",
    "\n",
    "# Set random seed.\n",
    "set.seed(3145)\n"
   ],
   "id": "3b10bc52-ad29-4319-b220-f988580dc3d0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an SVM model specification and workflow, indicating the model hyperparameters $\\sigma$ (or `rbf_sigma`) and `cost`. The `rbf_sigma` parameter controls the influence of individual training examples, while the `cost` parameter controls the trade-off between achieving a low training error and a low testing error, which affects the model’s ability to generalize. To optimize our model, we will use the `tune::tune()` function to find the optimal values of these parameters in terms of model accuracy."
   ],
   "id": "1bf3b4bf-63c1-46ed-9ae1-b5cfce79956c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model specification.\n",
    "svm_model_spec <-\n",
    "  parsnip::svm_rbf(\n",
    "    cost = tune::tune(),\n",
    "    rbf_sigma = tune::tune()\n",
    "  ) |>\n",
    "  parsnip::set_engine('kernlab') |>\n",
    "  parsnip::set_mode('classification')\n",
    "\n",
    "# Create model workflow.\n",
    "svm_workflow <- workflows::workflow() |>\n",
    "  workflows::add_model(svm_model_spec) |>\n",
    "  workflows::add_recipe(data_rec)\n"
   ],
   "id": "1ff9928e-a3ee-4ee1-9ff6-13b015f7d538"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning and Fitting\n",
    "\n",
    "As we did for KNN, we use parallel computing to fine-tuning our model using the $10$-fold cross-validation we set up earlier. We end this section by selecting the best model based on accuracy."
   ],
   "id": "b6038e7b-357c-4340-bebb-f56f1a5df9eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10.884 sec elapsed"
     ]
    }
   ],
   "source": [
    "#' Check number of available cores.\n",
    "cores_no <- parallel::detectCores() - 1\n",
    "\n",
    "#' Start timer.\n",
    "tictoc::tic()\n",
    "\n",
    "# Create and register clusters.\n",
    "clusters <- parallel::makeCluster(cores_no)\n",
    "doParallel::registerDoParallel(clusters)\n",
    "\n",
    "# Fine-tune the model params.\n",
    "svm_res <- tune::tune_grid(\n",
    "  object = svm_workflow,\n",
    "  resamples = data_cross_val,\n",
    "  control = tune::control_resamples(save_pred = TRUE)\n",
    ")\n",
    "\n",
    "# Select the best fit based on accuracy.\n",
    "svm_best_fit <- \n",
    "  svm_res |> \n",
    "  tune::select_best(metric = 'accuracy')\n",
    "\n",
    "# Finalize the workflow with the best parameters.\n",
    "svm_final_workflow <- \n",
    "  svm_workflow |>\n",
    "  tune::finalize_workflow(svm_best_fit)\n",
    "\n",
    "# Fit the final model using the best parameters.\n",
    "svm_final_fit <- \n",
    "  svm_final_workflow |> \n",
    "  tune::last_fit(data_split)\n",
    "\n",
    "# Stop clusters.\n",
    "parallel::stopCluster(clusters)\n",
    "\n",
    "# Stop timer.\n",
    "tictoc::toc()\n"
   ],
   "id": "6e1b9639-3038-4eb0-81f5-c45a9c5ec595"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "We then apply our selected model to the test set. The final metrics are given in @tbl-svm-performance-html."
   ],
   "id": "122cc69f-1721-42d2-99ea-45584c0a86a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best fit to make predictions on the test data.\n",
    "svm_pred <- \n",
    "  svm_final_fit |> \n",
    "  tune::collect_predictions() |>\n",
    "  dplyr::mutate(truth = factor(.pred_class))\n"
   ],
   "id": "ffcc263d-d711-4381-ae6f-25be48d4ed8b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metrics table.\n",
    "svm_metrics_table <- list(\n",
    "  'Accuracy' = yardstick::accuracy_vec(truth = svm_pred[['.pred_class']],\n",
    "                                       estimate = test_outcome),\n",
    "  'Precision' = yardstick::precision_vec(truth = svm_pred[['.pred_class']],\n",
    "                                         estimate = test_outcome),\n",
    "  'Recall' = yardstick::recall_vec(truth = svm_pred[['.pred_class']],\n",
    "                                   estimate = test_outcome),\n",
    "  'Specificity' = yardstick::specificity_vec(truth = svm_pred[['.pred_class']],\n",
    "                                            estimate = test_outcome)\n",
    ") |>\n",
    "  dplyr::bind_cols() |>\n",
    "  tidyr::pivot_longer(cols = dplyr::everything(), names_to = 'Metric', values_to = 'Value') |>\n",
    "  dplyr::mutate(Value = round(Value*100, 1))\n",
    "\n",
    "readr::write_csv(x = svm_metrics_table, file = here::here('data', 'svm-metrics.csv'))\n"
   ],
   "id": "76fd651d-fb37-40c1-9ce6-05aa8956c6ce"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
