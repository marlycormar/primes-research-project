{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "## Artificial Neural Network\n",
    "\n",
    "### Model Description\n",
    "\n",
    "Artificial Neural Networks (ANNs) are a class of machine learning algorithms inspired by the structure and function of the human brain. They consist of interconnected layers of nodes, or neurons, which process input data to perform tasks such as classification, regression, and pattern recognition. ANNs are particularly effective for complex tasks like image and speech recognition, natural language processing, financial forecasting, and medical diagnosis.\n",
    "\n",
    "An ANN is composed of multiple layers, including an input layer, one or more hidden layers, and an output layer. The input layer receives the raw data, the hidden layers process the data through various transformations, and the output layer produces the final prediction or classification. Each connection between neurons has an associated weight, and each neuron has a bias term. These parameters are adjusted during the training process to minimize the error in predictions.\n",
    "\n",
    "The training process of an ANN involves forward propagation, where input data is passed through the network layer by layer. Each neuron applies an activation function to compute its output, introducing non-linearity to help the network learn complex patterns. The loss, or error, between the network’s output and the true target values is calculated using a loss function. Through backpropagation, the loss is propagated backward through the network, and the weights and biases are adjusted using an optimization algorithm like gradient descent.\n",
    "\n",
    "ANNs offer significant advantages, including flexibility in modeling complex relationships and the ability to scale for large datasets and intricate tasks. Their ability to learn and generalize from data makes them powerful tools in various applications, driving advancements in fields ranging from technology and finance to healthcare and beyond.\n",
    "\n",
    "### Model Workflow"
   ],
   "id": "1e4ddf49-4817-4350-acfc-72778f38abfe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "✔ broom        1.0.6      ✔ recipes      1.0.10\n",
      "✔ dials        1.2.1      ✔ rsample      1.2.1 \n",
      "✔ dplyr        1.1.4      ✔ tibble       3.2.1 \n",
      "✔ ggplot2      3.5.1      ✔ tidyr        1.3.1 \n",
      "✔ infer        1.0.7      ✔ tune         1.2.1 \n",
      "✔ modeldata    1.3.0      ✔ workflows    1.1.4 \n",
      "✔ parsnip      1.2.1      ✔ workflowsets 1.1.0 \n",
      "✔ purrr        1.0.2      ✔ yardstick    1.3.1 "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "✖ purrr::discard() masks scales::discard()\n",
      "✖ dplyr::filter()  masks stats::filter()\n",
      "✖ dplyr::lag()     masks stats::lag()\n",
      "✖ recipes::step()  masks stats::step()\n",
      "• Search for functions across packages at https://www.tidymodels.org/find/"
     ]
    }
   ],
   "source": [
    "library(tidymodels)\n"
   ],
   "id": "2c18bc9c-bf9f-427d-9080-41625bfaac91"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by specifying the ANN model and creating the model workflow. Specifically, we will define a multilayer perceptron model (i.e., a single-layer, feed-forward neural network). The key parameters we will set include the number of epochs (or training iterations), the number of hidden units, the penalty (or weight decay), and the learning rate."
   ],
   "id": "b1d83d35-8a27-4a7b-8b1c-4d3e5762bda4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model specification.\n",
    "ann_model_spec <-\n",
    "  parsnip::mlp(\n",
    "    epochs = tune::tune(),\n",
    "    hidden_units = tune::tune(),\n",
    "    penalty = tune::tune(),\n",
    "    learn_rate = 0.1\n",
    "  ) |>\n",
    "  parsnip::set_engine('nnet') |>\n",
    "  parsnip::set_mode('classification')\n",
    "\n",
    "# Create model workflow.\n",
    "ann_workflow <- workflows::workflow() |>\n",
    "  workflows::add_model(ann_model_spec) |>\n",
    "  workflows::add_recipe(data_rec)\n"
   ],
   "id": "2bdc168d-fdbd-41d1-90cc-f4be943a6689"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning and Fitting\n",
    "\n",
    "We will proceed to tune all the parameters except for the learning rate. This is because the `nnet` package does not support tuning the learning rate."
   ],
   "id": "d1a57f41-90f7-480c-8449-c9e6f755c74b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9.753 sec elapsed"
     ]
    }
   ],
   "source": [
    "#' Check number of available cores.\n",
    "cores_no <- parallel::detectCores() - 1\n",
    "\n",
    "#' Start timer.\n",
    "tictoc::tic()\n",
    "\n",
    "# Create and register clusters.\n",
    "clusters <- parallel::makeCluster(cores_no)\n",
    "doParallel::registerDoParallel(clusters)\n",
    "\n",
    "# Fine-tune the model params.\n",
    "ann_res <- tune::tune_grid(\n",
    "  object = ann_workflow,\n",
    "  resamples = data_cross_val,\n",
    "  control = tune::control_resamples(save_pred = TRUE)\n",
    ")\n",
    "\n",
    "# Select the best fit based on accuracy.\n",
    "ann_best_fit <- \n",
    "  ann_res |> \n",
    "  tune::select_best(metric = 'accuracy')\n",
    "\n",
    "# Finalize the workflow with the best parameters.\n",
    "ann_final_workflow <- \n",
    "  ann_workflow |>\n",
    "  tune::finalize_workflow(ann_best_fit)\n",
    "\n",
    "# Fit the final model using the best parameters.\n",
    "ann_final_fit <- \n",
    "  ann_final_workflow |> \n",
    "  tune::last_fit(data_split)\n",
    "\n",
    "# Stop clusters.\n",
    "parallel::stopCluster(clusters)\n",
    "\n",
    "# Stop timer.\n",
    "tictoc::toc()\n"
   ],
   "id": "7a3763d6-8eba-4535-b708-955559c12284"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "We then apply our selected model to the test set. The final metrics are given in @tbl-ann-performance-html."
   ],
   "id": "e24cec3e-49a9-48f6-bd26-6b556b33f3dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best fit to make predictions on the test data.\n",
    "ann_pred <- \n",
    "  ann_final_fit |> \n",
    "  tune::collect_predictions() |>\n",
    "  dplyr::mutate(truth = factor(.pred_class))\n"
   ],
   "id": "7ecc5efb-eeb5-441b-9960-354ddcea8a40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metrics table.\n",
    "ann_metrics_table <- list(\n",
    "  'Accuracy' = yardstick::accuracy_vec(truth = ann_pred[['.pred_class']],\n",
    "                                       estimate = test_outcome),\n",
    "  'Precision' = yardstick::precision_vec(truth = ann_pred[['.pred_class']],\n",
    "                                         estimate = test_outcome),\n",
    "  'Recall' = yardstick::recall_vec(truth = ann_pred[['.pred_class']],\n",
    "                                   estimate = test_outcome),\n",
    "  'Specificity' = yardstick::specificity_vec(truth = ann_pred[['.pred_class']],\n",
    "                                            estimate = test_outcome)\n",
    ") |>\n",
    "  dplyr::bind_cols() |>\n",
    "  tidyr::pivot_longer(cols = dplyr::everything(), names_to = 'Metric', values_to = 'Value') |>\n",
    "  dplyr::mutate(Value = round(Value*100, 1))\n",
    "\n",
    "readr::write_csv(x = ann_metrics_table, file = here::here('data', 'ann-metrics.csv'))\n"
   ],
   "id": "1db0d287-5ce6-45ec-99ce-5142aec11c24"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
